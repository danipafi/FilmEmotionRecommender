{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9787c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 08:38:45.719 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-13 08:38:45.855 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/danielebelmiro/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-13 08:38:45.856 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: /Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/df_final.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dask/backends.py:136\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dask/dataframe/io/parquet/core.py:543\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, use_nullable_dtypes, dtype_backend, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, blocksize, aggregate_files, parquet_file_extension, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m     blocksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m read_metadata_result \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_metadata(\n\u001b[1;32m    544\u001b[0m     fs,\n\u001b[1;32m    545\u001b[0m     paths,\n\u001b[1;32m    546\u001b[0m     categories\u001b[38;5;241m=\u001b[39mcategories,\n\u001b[1;32m    547\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m    548\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[1;32m    549\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    550\u001b[0m     gather_statistics\u001b[38;5;241m=\u001b[39mcalculate_divisions,\n\u001b[1;32m    551\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[1;32m    552\u001b[0m     split_row_groups\u001b[38;5;241m=\u001b[39msplit_row_groups,\n\u001b[1;32m    553\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39mblocksize,\n\u001b[1;32m    554\u001b[0m     aggregate_files\u001b[38;5;241m=\u001b[39maggregate_files,\n\u001b[1;32m    555\u001b[0m     ignore_metadata_file\u001b[38;5;241m=\u001b[39mignore_metadata_file,\n\u001b[1;32m    556\u001b[0m     metadata_task_size\u001b[38;5;241m=\u001b[39mmetadata_task_size,\n\u001b[1;32m    557\u001b[0m     parquet_file_extension\u001b[38;5;241m=\u001b[39mparquet_file_extension,\n\u001b[1;32m    558\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset_options,\n\u001b[1;32m    559\u001b[0m     read\u001b[38;5;241m=\u001b[39mread_options,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_options,\n\u001b[1;32m    561\u001b[0m )\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# In the future, we may want to give the engine the\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# option to return a dedicated element for `common_kwargs`.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# However, to avoid breaking the API, we just embed this\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# data in the first element of `parts` for now.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# The logic below is inteded to handle backward and forward\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# compatibility with a user-defined engine.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dask/dataframe/io/parquet/arrow.py:534\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_metadata\u001b[0;34m(cls, fs, paths, categories, index, use_nullable_dtypes, dtype_backend, gather_statistics, filters, split_row_groups, blocksize, aggregate_files, ignore_metadata_file, metadata_task_size, parquet_file_extension, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# Stage 1: Collect general dataset information\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m dataset_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_dataset_info(\n\u001b[1;32m    535\u001b[0m     paths,\n\u001b[1;32m    536\u001b[0m     fs,\n\u001b[1;32m    537\u001b[0m     categories,\n\u001b[1;32m    538\u001b[0m     index,\n\u001b[1;32m    539\u001b[0m     gather_statistics,\n\u001b[1;32m    540\u001b[0m     filters,\n\u001b[1;32m    541\u001b[0m     split_row_groups,\n\u001b[1;32m    542\u001b[0m     blocksize,\n\u001b[1;32m    543\u001b[0m     aggregate_files,\n\u001b[1;32m    544\u001b[0m     ignore_metadata_file,\n\u001b[1;32m    545\u001b[0m     metadata_task_size,\n\u001b[1;32m    546\u001b[0m     parquet_file_extension,\n\u001b[1;32m    547\u001b[0m     kwargs,\n\u001b[1;32m    548\u001b[0m )\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# Stage 2: Generate output `meta`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dask/dataframe/io/parquet/arrow.py:1049\u001b[0m, in \u001b[0;36mArrowDatasetEngine._collect_dataset_info\u001b[0;34m(cls, paths, fs, categories, index, gather_statistics, filters, split_row_groups, blocksize, aggregate_files, ignore_metadata_file, metadata_task_size, parquet_file_extension, kwargs)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     ds \u001b[38;5;241m=\u001b[39m pa_ds\u001b[38;5;241m.\u001b[39mdataset(\n\u001b[1;32m   1050\u001b[0m         paths,\n\u001b[1;32m   1051\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39m_wrapped_fs(fs),\n\u001b[1;32m   1052\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_processed_dataset_kwargs,\n\u001b[1;32m   1053\u001b[0m     )\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# Get file_frag sample and extract physical_schema\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyarrow/dataset.py:765\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _filesystem_dataset(source, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(elem, Dataset) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyarrow/dataset.py:443\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 443\u001b[0m     fs, paths_or_selector \u001b[38;5;241m=\u001b[39m _ensure_multiple_sources(source, filesystem)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyarrow/dataset.py:362\u001b[0m, in \u001b[0;36m_ensure_multiple_sources\u001b[0;34m(paths, filesystem)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mNotFound:\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(info\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mDirectory:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/df_final.parquet",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 165\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Run the application\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 153\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<h1 class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>üé¨ Movie Recommendation System</h1>\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    149\u001b[0m     unsafe_allow_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m movies, reviews, df_final \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# User input for recommendations\u001b[39;00m\n\u001b[1;32m    157\u001b[0m favorite_movie \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtext_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the name of your favorite movie:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py:168\u001b[0m, in \u001b[0;36mmake_cached_func_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(info\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cached_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py:197\u001b[0m, in \u001b[0;36mCachedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mshow_spinner \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mshow_spinner, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message, _cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 197\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_create_cached_value(args, kwargs)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_create_cached_value(args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py:224\u001b[0m, in \u001b[0;36mCachedFunc._get_or_create_cached_value\u001b[0;34m(self, func_args, func_kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CacheKeyNotFoundError:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cache_miss(cache, value_key, func_args, func_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py:280\u001b[0m, in \u001b[0;36mCachedFunc._handle_cache_miss\u001b[0;34m(self, cache, value_key, func_args, func_kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# We acquired the lock before any other thread. Compute the value!\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mcached_message_replay_ctx\u001b[38;5;241m.\u001b[39mcalling_cached_function(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mallow_widgets\n\u001b[1;32m    279\u001b[0m ):\n\u001b[0;32m--> 280\u001b[0m     computed_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# We've computed our value, and now we need to write it back to the cache\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# along with any \"replay messages\" that were generated during value computation.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mcached_message_replay_ctx\u001b[38;5;241m.\u001b[39m_most_recent_messages\n",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m movies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/movies_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Carregar a matriz reduzida\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m df_final \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_final.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcompute()  \u001b[38;5;66;03m# Convertendo para pandas para facilitar a valida√ß√£o\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m movies, reviews, df_final\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dask/backends.py:138\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod registered to the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: /Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/df_final.parquet"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import re\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "import ast\n",
    "import base64\n",
    "\n",
    "# Set page configuration to \"wide\"\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# Function to convert a file to base64\n",
    "def get_base64_of_bin_file(bin_file):\n",
    "    with open(bin_file, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    return base64.b64encode(data).decode()\n",
    "\n",
    "# Load header image as base64\n",
    "header_image_path = \"/Users/danielebelmiro/Downloads/Mr_ Observer - Barancan Daƒüƒ±stan.jpeg\"\n",
    "header_image_base64 = get_base64_of_bin_file(header_image_path)\n",
    "\n",
    "# CSS for cards, header, sidebar, titles and background\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "/* Main title with text stroke (pink) */\n",
    ".title {\n",
    "    font-size: 53px;\n",
    "    text-align: left; \n",
    "    color: #FF69B4;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    margin-bottom: 10px;\n",
    "    -webkit-text-stroke: 1px black;\n",
    "}\n",
    "\n",
    "/* Subtitle */\n",
    ".subtitle {\n",
    "    font-size: 18px;\n",
    "    text-align: left;\n",
    "    color: #333;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    margin-bottom: 30px;\n",
    "}\n",
    "\n",
    "/* Header container */\n",
    ".header-container {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    justify-content: space-between;\n",
    "    min-width: 800px;\n",
    "    max-width: 1200px;\n",
    "    margin: auto;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    "\n",
    "/* Card style with light beige background */\n",
    ".card {\n",
    "    background-color: #FFF8E7;  /* Light beige */\n",
    "    padding: 15px;\n",
    "    margin: 10px 0;\n",
    "    border-radius: 8px;\n",
    "    border: 2px solid #ccc;\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "}\n",
    "\n",
    ".card-title {\n",
    "    font-size: 24px;\n",
    "    font-weight: bold;\n",
    "    margin-bottom: 10px;\n",
    "    text-align: left;\n",
    "}\n",
    "\n",
    "/* Section headings (lilac for section headings) */\n",
    ".section-heading {\n",
    "    font-size: 32px;\n",
    "    font-weight: bold;\n",
    "    color: #C8A2C8;\n",
    "    -webkit-text-stroke: 1px black;\n",
    "    margin-bottom: 20px;\n",
    "    text-align: left;\n",
    "}\n",
    "\n",
    "/* Sidebar adjustments */\n",
    ".css-1d391kg { \n",
    "    max-width: 300px;\n",
    "}\n",
    ".css-1d391kg > div { \n",
    "    max-width: 300px;\n",
    "}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s]', '', name)\n",
    "    return name.lower().strip()\n",
    "\n",
    "def generate_rotten_tomatoes_url(movie_id):\n",
    "    return f\"https://www.rottentomatoes.com/m/{movie_id}\"\n",
    "\n",
    "def get_movie_poster_url(movie_id):\n",
    "    url = f\"https://www.rottentomatoes.com/m/{movie_id}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    meta_tag = soup.find('meta', property=\"og:image\")\n",
    "    if meta_tag and meta_tag.get('content'):\n",
    "        return meta_tag['content']\n",
    "    poster_img = soup.find('img', {'class': 'posterImage'})\n",
    "    if poster_img and 'src' in poster_img.attrs:\n",
    "        return poster_img['src']\n",
    "    return None\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    reviews = pd.read_csv('/Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/reviews_emotions.csv')\n",
    "    movies = pd.read_csv('/Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/movies_final.csv')\n",
    "    movies['genre'] = movies['genre'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    movies['emotions'] = movies['emotions'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df_final_clean = pd.read_csv('/Users/danielebelmiro/Data_Analytics_Bootcamp/Rotten/df_final_clean.csv')\n",
    "    return movies, reviews, df_final_clean\n",
    "\n",
    "def render_movie_card(movie, poster_url, is_favorite=False):\n",
    "    \"\"\"\n",
    "    Renders a card with the movie information.\n",
    "    If is_favorite is True, uses a larger poster and omits the similarity score.\n",
    "    The movie title is displayed prominently (aligned to the left).\n",
    "    \"\"\"\n",
    "    poster_width = 240\n",
    "    similarity_line = \"\" if is_favorite else f\"<p><strong>üîó Similarity Score:</strong> {movie.get('score', 0):.5f}</p>\"\n",
    "    if isinstance(movie['emotions'], (list, tuple)):\n",
    "        emotional_profile_str = \", \".join([f\"{mood}: {percentage:.1f}%\" for mood, percentage in movie['emotions']])\n",
    "    else:\n",
    "        emotional_profile_str = movie['emotions']\n",
    "    card_html = f\"\"\"\n",
    "    <div class=\"card\">\n",
    "      <div class=\"card-title\">üé¨ {movie['title']}</div>\n",
    "      <div style=\"display: flex; align-items: center;\">\n",
    "        <div style=\"flex: 1;\">\n",
    "          <img src=\"{poster_url}\" width=\"{poster_width}\" style=\"border-radius: 5px;\">\n",
    "        </div>\n",
    "        <div style=\"flex: 2; padding-left: 15px;\">\n",
    "          <p><strong>üé• Director:</strong> {movie['director']}</p>\n",
    "          <p><strong>üåç Language:</strong> {movie['originalLanguage']}</p>\n",
    "          <p><strong>‚è≥ Duration:</strong> {movie['runtimeMinutes']} min</p>\n",
    "          <p><strong>üé≠ Genre:</strong> {\", \".join(movie['genre']) if isinstance(movie['genre'], (list, tuple)) else movie['genre']}</p>\n",
    "          <p><strong>üìÖ Year:</strong> {movie['release_year']}</p>\n",
    "          <p><strong>üçÖ Tomatometer:</strong> {movie['tomatoMeter']}%</p>\n",
    "          <p><strong>üéüÔ∏è Audience Score:</strong> {movie['audienceScore']}%</p>\n",
    "          {similarity_line}\n",
    "          <p><strong>‚ù§Ô∏è Emotional Profile:</strong> {emotional_profile_str}</p>\n",
    "          <p><a href=\"{generate_rotten_tomatoes_url(movie['id'])}\" target=\"_blank\">üîó Link to Rotten Tomatoes</a></p>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    card_html = \" \".join(card_html.splitlines())\n",
    "    st.markdown(card_html, unsafe_allow_html=True)\n",
    "\n",
    "def recommend_similar_movies(df_final_clean, movies, reviews, favorite_movie, top_n=5):\n",
    "    movies = movies.copy()\n",
    "    favorite_movie_normalized = normalize_name(favorite_movie)\n",
    "    matching_movies = movies[movies['title_normalized'] == favorite_movie_normalized]\n",
    "    if matching_movies.empty:\n",
    "        st.error(f\"‚ùå The movie '{favorite_movie}' was not found. Please check the name and try again.\")\n",
    "        return None\n",
    "    favorite_movie_id = matching_movies.iloc[0]['id']\n",
    "    favorite_movie_title = matching_movies.iloc[0]['title']\n",
    "    st.success(f\"‚úÖ Movie found: {favorite_movie_title} (ID: {favorite_movie_id})\")\n",
    "    fav_movie = matching_movies.iloc[0].to_dict()\n",
    "    fav_poster_url = get_movie_poster_url(favorite_movie_id)\n",
    "    st.markdown('<div class=\"section-heading\">Favorite Movie</div>', unsafe_allow_html=True)\n",
    "    render_movie_card(fav_movie, fav_poster_url, is_favorite=True)\n",
    "    st.markdown(\"<hr>\", unsafe_allow_html=True)\n",
    "    movie_similarities = df_final_clean[df_final_clean['id1'] == favorite_movie_id][['id2', 'score']]\n",
    "    movie_similarities = movie_similarities.sort_values(by='score', ascending=False)\n",
    "    top_recommendations = movie_similarities.head(top_n).reset_index(drop=True)\n",
    "    recommended_movies = top_recommendations.merge(movies, left_on='id2', right_on='id', how='left')\n",
    "    st.markdown('<div class=\"section-heading\">Recommended Movies</div>', unsafe_allow_html=True)\n",
    "    for _, row in recommended_movies.iterrows():\n",
    "        movie_data = row.to_dict()\n",
    "        poster_url = get_movie_poster_url(movie_data['id'])\n",
    "        render_movie_card(movie_data, poster_url, is_favorite=False)\n",
    "    return recommended_movies\n",
    "\n",
    "def main():\n",
    "    header_html = f\"\"\"\n",
    "    <div class=\"header-container\">\n",
    "        <div style=\"flex: 3;\">\n",
    "            <h1 class=\"title\">\n",
    "                <span style=\"white-space: nowrap;\">Welcome To Your Ultimate</span><br>\n",
    "                <span style=\"white-space: nowrap;\">Film Emotion Recommender!</span>\n",
    "            </h1>\n",
    "            <p class=\"subtitle\">üé¨ Find movie recommendations with a similar emotional profile to your favorite movie.<br>üçø The model is based on sentiment analysis of Rotten Tomatoes reviews.</p>\n",
    "        </div>\n",
    "        <div style=\"flex: 1; display: flex; align-items: center; justify-content: flex-end;\">\n",
    "            <img src=\"data:image/jpeg;base64,{header_image_base64}\" width=\"350\">\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    st.markdown(header_html, unsafe_allow_html=True)\n",
    "    \n",
    "    favorite_movie = st.sidebar.text_input(\"üé¨ Enter the name of your favorite movie:\")\n",
    "    top_n = st.sidebar.slider(\"üî¢ How many recommendations do you want?\", 1, 5, 3)\n",
    "    \n",
    "    movies, reviews, df_final_clean = load_data()\n",
    "    if favorite_movie:\n",
    "        recommend_similar_movies(df_final_clean, movies, reviews, favorite_movie, top_n)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea41779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
